{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import  Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', train=False,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "n_epochs = n_iters/(len(train_dataset)/ batch_size)\n",
    "n_epochs = int(n_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FeedForwardNeuralModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        #out = self.sigmoid(out)\n",
    "        #out = self.tanh(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "\n",
    "model = FeedForwardNeuralModel(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f15051ff0a0>\n",
      "4\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "#FC 1 parameters\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "#FC 1 bias\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "#FC 2 parameters\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "#FC 1 bias\n",
    "print(list(model.parameters())[3].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 500, Loss 0.41096046566963196, accuraracy 91\n",
      "iteration 1000, Loss 0.342685341835022, accuraracy 92\n",
      "iteration 1500, Loss 0.22424405813217163, accuraracy 93\n",
      "iteration 2000, Loss 0.12035635113716125, accuraracy 94\n",
      "iteration 2500, Loss 0.24518555402755737, accuraracy 95\n",
      "iteration 3000, Loss 0.13896068930625916, accuraracy 95\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #load images\n",
    "        \n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass to get output/logits\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        #calculate loss\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #getting gradients wrt parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #update parameters\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter +=1\n",
    "        if iter% 500 ==0:\n",
    "            #calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100* correct/total\n",
    "            print('iteration {}, Loss {}, accuraracy {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 hidden layers\n",
    "\n",
    "class FeedForwardNeuralNetModel1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FeedForwardNeuralNetModel1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        #self.tanh = nn.Tanh()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        #out = self.sigmoid(out)\n",
    "        #out = self.tanh(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "\n",
    "model1 = FeedForwardNeuralNetModel1(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f1501bce570>\n",
      "6\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model1.parameters())))\n",
    "#FC 1 parameters\n",
    "print(list(model1.parameters())[0].size())\n",
    "\n",
    "#FC 1 bias\n",
    "print(list(model1.parameters())[1].size())\n",
    "\n",
    "#FC 2 parameters\n",
    "print(list(model1.parameters())[2].size())\n",
    "\n",
    "#FC 1 bias\n",
    "print(list(model1.parameters())[3].size())\n",
    "\n",
    "#FC 3 parameters\n",
    "print(list(model1.parameters())[4].size())\n",
    "\n",
    "#FC 3 bias\n",
    "print(list(model1.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 500, Loss 0.09714299440383911, accuraracy 96\n",
      "iteration 1000, Loss 0.1370740681886673, accuraracy 96\n",
      "iteration 1500, Loss 0.06508693844079971, accuraracy 96\n",
      "iteration 2000, Loss 0.16157571971416473, accuraracy 96\n",
      "iteration 2500, Loss 0.08667043596506119, accuraracy 97\n",
      "iteration 3000, Loss 0.07577082514762878, accuraracy 97\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #load images\n",
    "        \n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass to get output/logits\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        #calculate loss\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #getting gradients wrt parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #update parameters\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter +=1\n",
    "        if iter% 500 ==0:\n",
    "            #calculate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100* correct/total\n",
    "            print('iteration {}, Loss {}, accuraracy {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
